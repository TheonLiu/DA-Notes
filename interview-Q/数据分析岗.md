<!-- TOC -->

- [一：通用](#一通用)
  - [1. 你有什么优点](#1-你有什么优点)
  - [2. 数据分析日常工作内容以及工具](#2-数据分析日常工作内容以及工具)
  - [3. 你最近在看什么书](#3-你最近在看什么书)
  - [4.你有什么问题想问](#4你有什么问题想问)
  - [5.你眼中的数据分析师是什么样的？](#5你眼中的数据分析师是什么样的)
  - [谈一下对数据分析的理解？](#谈一下对数据分析的理解)
  - [6.你为什么想做数据分析](#6你为什么想做数据分析)
  - [7.数据分析报告你会怎么写](#7数据分析报告你会怎么写)
  - [8.常用的app及优缺点，改进：](#8常用的app及优缺点改进)
- [二：业务](#二业务)
  - [维度拆解](#维度拆解)
  - [1.竞品分析：](#1竞品分析)
  - [2.上升/下降类原因分析问题解决问题解决流程:](#2上升下降类原因分析问题解决问题解决流程)
  - [3.数据异常类问题的解决流程](#3数据异常类问题的解决流程)
  - [4.复合指标分析（e.g ROI = 利润/成本）](#4复合指标分析eg-roi--利润成本)
    - [喜马拉雅app](#喜马拉雅app)
  - [4.功能是否上线](#4功能是否上线)
  - [5. 新功能上线后，如何用数据评估它是否成功？](#5-新功能上线后如何用数据评估它是否成功)
  - [6.预测类](#6预测类)
    - [如何做电商平台的销量预测](#如何做电商平台的销量预测)
    - [影响销量预测结果的要素需要考虑哪些](#影响销量预测结果的要素需要考虑哪些)
  - [估算一个广告给头条带来多少新增用户](#估算一个广告给头条带来多少新增用户)
  - [6.100万预算，红包补贴，增加外卖订单量。](#6100万预算红包补贴增加外卖订单量)
  - [RFM模型](#rfm模型)
  - [数据埋点](#数据埋点)
  - [2.在搜索中增加保留历史浏览记录这个功能](#2在搜索中增加保留历史浏览记录这个功能)
    - [作为数据分析师会怎么去评估这个功能是否应该上线](#作为数据分析师会怎么去评估这个功能是否应该上线)
    - [需要去看那些指标](#需要去看那些指标)
    - [假设现在这个功能已经上线了，需要优化，你有哪些优化的想法](#假设现在这个功能已经上线了需要优化你有哪些优化的想法)
  - [3.在北京开一家水果店会考虑哪些因素？如果要开分店还要考虑啥因素？](#3在北京开一家水果店会考虑哪些因素如果要开分店还要考虑啥因素)
  - [4.UBER现在有一个发放优惠券的活动，该如何评估这个活动带来的ROI 的影响](#4uber现在有一个发放优惠券的活动该如何评估这个活动带来的roi-的影响)
  - [5.然后问有没有觉得哪个APP的交互界面或者用户体验不是很好的](#5然后问有没有觉得哪个app的交互界面或者用户体验不是很好的)
  - [7.引入一个新功能后，如何评价该新功能的有效性](#7引入一个新功能后如何评价该新功能的有效性)
  - [8.日活(DAU)：APP指标体系的搭建，用户的LTV，如何预测，用户粘性怎么看，怎么提高APP用户粘性，APP新功能如何评估](#8日活dauapp指标体系的搭建用户的ltv如何预测用户粘性怎么看怎么提高app用户粘性app新功能如何评估)
  - [11.抖音要现在有两个新功能，直播跟私信](#11抖音要现在有两个新功能直播跟私信)
    - [你怎么利用这两个功能的现状来评估，应该重点推广哪一个功能（面试官有提示，这两个功能类型不同之类的）](#你怎么利用这两个功能的现状来评估应该重点推广哪一个功能面试官有提示这两个功能类型不同之类的)
    - [你推广了这个功能之后，怎么评估推广的效果](#你推广了这个功能之后怎么评估推广的效果)
  - [数据埋点分类](#数据埋点分类)
  - [app相关：](#app相关)
  - [种西瓜问题](#种西瓜问题)
  - [留存：](#留存)
  - [异常指标归因：](#异常指标归因)
  - [电商数据指标搭建](#电商数据指标搭建)
  - [对用户进行分层](#对用户进行分层)
- [三. SQL：](#三-sql)
  - [题目集](#题目集)
  - [1.	除了distinct外还有什么方法去重](#1除了distinct外还有什么方法去重)
  - [2.	窗口函数：](#2窗口函数)
  - [3.	partition by 和 group by 的区别](#3partition-by-和-group-by-的区别)
  - [4.	窗口函数里的排序函数](#4窗口函数里的排序函数)
  - [5. 窗口函数里的聚合函数](#5-窗口函数里的聚合函数)
  - [6. 窗口函数偏移函数](#6-窗口函数偏移函数)
  - [7.	给主播id，主播类型，主播粉丝数，求每个类型主播粉丝数top100](#7给主播id主播类型主播粉丝数求每个类型主播粉丝数top100)
  - [8.	sql执行顺序：](#8sql执行顺序)
  - [9.  INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN](#9--inner-join-left-join-right-join-full-join)
  - [10. 等值连接，笛卡尔积](#10-等值连接笛卡尔积)
  - [11.  UNION 和UNION ALL的区别](#11--union-和union-all的区别)
  - [12.  SQL行列转换](#12--sql行列转换)
  - [count(1)：](#count1)
  - [DATE_SUB(date,INTERVAL expr type)](#date_subdateinterval-expr-type)
  - [判断空](#判断空)
  - [Ifnull (expression, alt_value)](#ifnull-expression-alt_value)
  - [去语义](#去语义)
  - [lead](#lead)
  - [delete语句](#delete语句)
  - [日期](#日期)
  - [主键/外键](#主键外键)
- [四. Hive：](#四-hive)
- [五. 统计：](#五-统计)
  - [1.	皮尔森相关系数以及如何解读，相关、独立、线性相关区别](#1皮尔森相关系数以及如何解读相关独立线性相关区别)
  - [2. 讲一下A/B实验](#2-讲一下ab实验)
    - [定义](#定义)
    - [好处](#好处)
    - [如何分组](#如何分组)
  - [3.	贝叶斯公式](#3贝叶斯公式)
  - [4.	协方差的含义，协方差和相关系数的关系](#4协方差的含义协方差和相关系数的关系)
- [六：机器学习：](#六机器学习)
  - [1. 数据收集与探索性分析](#1-数据收集与探索性分析)
    - [如何看待基础性的工作，如数据清洗、数据抽取这些？](#如何看待基础性的工作如数据清洗数据抽取这些)
  - [2. 数据预处理与特征工程](#2-数据预处理与特征工程)
    - [特征工程怎么做的](#特征工程怎么做的)
    - [如果取出的数据中存在NULL，该如何做](#如果取出的数据中存在null该如何做)
    - [如果因为写的代码出现问题，导致取数出现NULL，该如何做](#如果因为写的代码出现问题导致取数出现null该如何做)
    - [数据清洗（完整性，唯一性，权威性，合法性，一致性）](#数据清洗完整性唯一性权威性合法性一致性)
    - [偏态分布怎么处理](#偏态分布怎么处理)
    - [归一化好处](#归一化好处)
    - [降维:](#降维)
    - [解释维度灾难，如何解决？](#解释维度灾难如何解决)
    - [knn如何处理高维特征？](#knn如何处理高维特征)
    - [kmeans如何处理高维特征？](#kmeans如何处理高维特征)
  - [3. 数据集分割](#3-数据集分割)
  - [4. 模型的选择与训练](#4-模型的选择与训练)
    - [机器学习分类：](#机器学习分类)
    - [线性非线性](#线性非线性)
    - [简单模型和复杂模型区别在哪](#简单模型和复杂模型区别在哪)
    - [softmax损失函数](#softmax损失函数)
    - [Linear Regression:](#linear-regression)
      - [线性回归优化问题:损失函数](#线性回归优化问题损失函数)
    - [逻辑回归](#逻辑回归)
      - [模型:](#模型)
      - [分类规则:](#分类规则)
      - [线性vs逻辑回归](#线性vs逻辑回归)
    - [svm:](#svm)
      - [Hard-margin SVM loss:](#hard-margin-svm-loss)
      - [Soft-margin SVM loss: (hinge loss)](#soft-margin-svm-loss-hinge-loss)
      - [LR和SVM区别](#lr和svm区别)
      - [LR，SVM中数据之间应该满足什么条件](#lrsvm中数据之间应该满足什么条件)
    - [Kernel](#kernel)
    - [Kmeans，KNN区别](#kmeansknn区别)
    - [Ensemble：将多个分类方法聚集在一起，以提高分类的准确率](#ensemble将多个分类方法聚集在一起以提高分类的准确率)
    - [GBDT过程](#gbdt过程)
    - [GBDT调参](#gbdt调参)
    - [GBDT和决策树(RF)](#gbdt和决策树rf)
    - [GBDT和XGBoost的区别（至少3方面）](#gbdt和xgboost的区别至少3方面)
    - [GBDT剪枝是怎么样的](#gbdt剪枝是怎么样的)
    - [树的剪枝](#树的剪枝)
    - [随机森林为什么随机](#随机森林为什么随机)
    - [决策树和随机森林优缺点](#决策树和随机森林优缺点)
    - [优化问题](#优化问题)
  - [5. 模型的评价](#5-模型的评价)
    - [模型评估指标的选择](#模型评估指标的选择)
    - [模型怎么判断过拟合，过拟合怎么了](#模型怎么判断过拟合过拟合怎么了)
    - [知道哪些距离，适用场景是什么](#知道哪些距离适用场景是什么)
    - [ROC曲线 与 AUC怎么算](#roc曲线-与-auc怎么算)
  - [6. 模型的部署](#6-模型的部署)

<!-- /TOC -->


# 一：通用
## 1. 你有什么优点
比较有毅力。因为我以前经常去玩一些极限运动，登雪山之类的，经常背着30多斤的登山包行走，晚上在一米深的雪上搭帐篷，白天行走十几个小时，晚上只睡三四个小时，而且没有退路，只能往前走，挑战身体的极限。  
比较喜欢和人沟通。因为以前组织各种活动，户外（规划行程，订车订酒店）讲座（学校和网红）。
## 2. 数据分析日常工作内容以及工具
常用数据分析的工具和套件  
Tableau，excel，spss，python，R，SQL
## 3. 你最近在看什么书
《深入浅出数据分析》  
《十次危机》温铁军：  
在人们通常的意识形态中，中国没有发生过经济危机，也不可能发生经济危机，最多只能算是经济波动，而不能算是危机。但作者认为，中国不仅发生过经济危机。而且中国自建国以来的六十年间，已经发生了8次经济危机，而这些危机均与国家工业化阶段性特征有关，政府是通过政策解决这些危机，解决这些危机产生的代价
## 4.你有什么问题想问
电商数据分析日常的工作   
如何自学数据分析中的业务问题   
是偏向中台一点的么？   
需要用到哪些机器学习模型   
需要对机器学习有多深的理解   
是否可以转正   
数据分析组的架构，汇报上级是谁，怎么和业务结合，平时的沟通方式，大组和小业务各有多少人
数据分析师的工作驱动来源：业务方？自己探索？谁驱动谁
小组内怎么分工，会有短期、长期的目标嘛
比如说最近比较关注的问题是什么
工作上的时间分配，沟通，确立方向，提数，做响应的分析各占多少？
和其他部门的合作情况
期望数据分析师应有的素质
怎么理解很多数据分析师觉得做得工作比较基础繁杂，没有一个“闪光点”的输出？（这个问题其实是百度第三轮业务面老板问我的，我觉得也是一个很好的讨论点）
数据分析组是什么时候成立的，现在是有了新增的hc嘛？（侧面了解业务，有些是有了新增业务需要更多的人手；有的是离职的坑）
如果我被录用，我会负责哪个业务（有的职位描述写的很明确就是某某方向，有的是进组之后再选择）
## 5.你眼中的数据分析师是什么样的？
##   谈一下对数据分析的理解？  
对行业数据搜集、整理、分析，并依据数据做出行业研究、评估和预测的人员
## 6.你为什么想做数据分析
对商业感兴趣，但又想充分利用上我计算的背景
## 7.数据分析报告你会怎么写
需求分析->数据采集->数据处理->数据分析(通过统计分析工具以及数据挖掘技术，对这些数据进行分析和研究，从中发现数据的内在关系和规律)->数据展现->寻找真因->提出解决方案->给予决策建议
## 8.常用的app及优缺点，改进：
1.	抖音
2.	头条
3.	飞书
4.	YouTube
5.	知乎
6.	抖音

# 二：业务
## 维度拆解
![维度拆解](https://img-blog.csdnimg.cn/20200705114002185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MDY5NjY3,size_16,color_FFFFFF,t_70)
## 1.竞品分析：
**使命 目标 市场定位
用户分析**（目标用户 现有用户 用户分层 相关指标 日活 月活 会员 点击率 在线时长 留存 拉新）
**内容分析**（视频种类 类型 时长 来源）
**经济分析**（盈利 营销 成本 活动）
**预测分析**
**PEST分析**
## 2.上升/下降类原因分析问题解决问题解决流程:
验证数据准确性-两层模型拆分-识别具体上升/下降群体-内部原因（产品本身）/外部原因分析（PEST模型）
先做数据异常原因的假设，后用数据验证假设
**第一步**：确认数据真实性
**第二步**：根据几个常见维度初步拆分数据（新/老用户，登录平台，版本，入口，登录渠道app/pc/小程序），区域，时间（淡旺季，日夜 产品周期）   
计算影响系数：每一项数据都要和以往正常值做对比，算出影响系数   
影响系数=(今日量-昨日量)/(今日总量-昨日总量)   
**第三步**：异常范围定位后，进一步做假设   
**内部**：
产品侧：功能调整，策略调整
技术侧：接口不稳定，系统故障，网页打不开
运营侧：运营策略，push效果，拉新渠道，投放推广，活动
**外部**：
PEST模型
**第四步**：细分假设，确立原因
1） GMV突然下降了20%，怎么分析？ 如何在众多因素中找到原因。
2） 淘宝某个店铺的营销额下降，该如何分析
3） 微信的日活下降，该如何分析
4） 如果头条这边发现日均使用时间突然降低，请问怎么分析
## 3.数据异常类问题的解决流程
**确定数据真实性-拆分数据维度-具体维度考察技术、产品、运营-进一步细化假设**
**定义流失用户**：行为（不登陆，付费），时间   
结合性别、级别用户，基于不同的流失阈值   
电商产品可以用购买行为来定义，下单频次，使用周期，询价，金额   
内容型：未登录，浏览。指标：停留时间 浏览量 评论   
创作者可以用用户发表来定义，即创作者多久未发表作品才算流失   
分析流失原因：竞品调研，用户调研，客户反馈系统，用户数据分析   
预警搭建：用户画像数据、用户行为数据、用户消费数据。新增阶段”、“活跃阶段”、“沉默阶段”、“流失阶段   
**定义预测的时间窗口**    
**召回**：   
发送优惠券及优惠金额调整   
增加app内的用户引导，场景化提醒文案等   
优化关联推荐   
个性化push文案、短信等   
其他针对特定流失原因的优化方案   
1) 在实习中做异动指标分析的例子   
2) 怎么判断即将流失用户
3)  划分用户生命周期： 
4) 如何做司机的流失预警
5) 流量预警
最低的阈值，完成的实值。拼多多优惠卷被薅羊毛
## 4.复合指标分析（e.g ROI = 利润/成本）
将多项式进行拆分，分析里面每一项可能产生的变动，包括分子，分母，因子
![用户数据指标](https://pic3.zhimg.com/80/v2-b13bcec1d057ccc9955ea422b9409af2_1440w.jpg "用户数据指标")

![行为数据指标](https://pic2.zhimg.com/v2-b4743c130065291bfc8d27c4e416272d_r.jpg)

![产品数据指标](https://pic2.zhimg.com/v2-46c2a07f9499571573e97c61826c13f5_r.jpg)
### 喜马拉雅app
**定位**：音频app，主要使用场景有：床上以及上下班路上，使用场景广泛且不影响人们手上的工作。
**第一阶段**: 找到用户的刚需。业务指标为：下载次数、收听时长等。->用于分析用户的需求是啥，是否能满足用户需求
**第二阶段**: 内测阶段。业务指标是：日活跃率、留存率等。->用于分析产品是否与用户有较大的粘性
**第三阶段**: 推广阶段。务指标是获客成本、日新增用户数、广告转化率、下载次数等->根据获客成本可以了解到推广效果好与坏，受众广不广等，根据日新增用户数、广告转化率、下载次数等，可分析不同渠道的推广效果。
**第四阶段**: 识别推广陷阱。业务指标：用户收听时长。->根据用户收听时长分析用户十分精准，减少不必要的推广资金投入。
## 4.功能是否上线
1) 什么场景下为用户解决什么问题？
   产品为用户提供的短期价值和长期价值！不能过早消耗剩余价值。eg：很多产品未很好解决用户想要的内容，就急于增加广告。
2) 该功能的增加是否符合公司以及产品的战略目标（公司处在什么阶段）？
   一般情况：互联网产品一定是聚焦于目标用户的。所以我们做的功能一定要符合产品本身的定位，为我们的目标人群服务，且是大多数目标人群
   特殊情况：支付宝作为支付产品，被要求加入各种社交功能，因为承担着阿里社交卡位的战略，需要扛起公司产品矩阵和战略目标。常见于公司的拳头产品。
3) 竞品有没有类似功能，效果如何?
   们要看竞品什么功能做的好，很好的解决了用户的某个场景的需求，并且效果得到了验证
4) 功能成功上线应具备哪些条件？
   研发人员够不够？需要其他团队配合，他们是否有时间支持？是否有相应的资质或者牌照？功能交付的时间？所有这些前置条件都决定这个功能能否做，做到什么地步
5) 团队是否有能力驾驭？
   eg：前期由于我们缺乏可运营变现的资源，同时缺乏后台开发人员以及运营人员，为了验证用户需求，我们先用免费常用网址，写死在客户端，小流量测试用户偏好。验证ok后，运营资源和开发人员到齐后，我们才开发了可运营模块，支持分区域进行投放的管理系统
6) 时机是否合适
   内部时机：做这个功能，能不能得到高层的支持？资源能否按时到位？团队现在是否能够驾驭？
   外部时机：竞争对手已然是寡头，建立了壁垒，形成用户习惯，还要花资金去重力推这块业务么？
7) 功能是否成功的评估标准？
   功能日活渗透率、功能留存、关联功能变化等。这样功能上线后，我们才能衡量要不要进一步投入资源优化，还是直接砍掉。
## 5. 新功能上线后，如何用数据评估它是否成功？
**上线前的准备**
1) **设计客群分组**
   设计实验组与对比组的作用是控制变量，保证数据验收的客观性
   1) 实验组要求
      除了新功能这个变量，其他的变量尽量与对比组保持一致，其他变量包括时间、渠道、用户状态等。客群数量方面，要足够说明效果
   2) 对比组要求
      没有新功能的变量，其他变量与实验组保持一致。客群数量方面，如果数据验收受客群数量影响，则实验组与对比组的数量要基本一致。
   3) 分组切量方法
      如果仅是上线了一个新功能，需要新版与旧版进行对比，可采用灰度方法，通过控流开关实现控量分组；如果是要做多个方案的对比测试，则可采用a/b测试方法
2) **设计数据指标体系**
    1）确定业务目标
    比如提升某个功能的转化率、提升某个业务的收入、提升功能留存等。
    2）按用户路径拆解数据指标
    用户数据：功能入口的流量、用户分群等
    行为数据：每个环节的行为转化数和转化率，例如功能使用的用户数、功能点击率、付费率等。
    业务数据：付费人数、收入、千次曝光收入等
    3）数据指标再次细分
    以上拆解的数据指标，为方便后面的深入分析，还可以按用户属性或事件属性再次拆解。例如按用户属性拆解，借款产品则可区分授信通过户、授信拒绝户；按事件属性拆解，区分登录方式、区分渠道等。
3) **提供埋点**
    1）埋点规范确定：埋点组成是页面+操作+区分类型的字段
    2）前端埋点和后端埋点：结果性事件一般前后端都埋，包括成功事件、失败事件（失败还要埋失败原因）；过程性事件一般是前端埋点。
    3）上报时机确定：大多数埋点的上报时机是比较显而易见的，所以文档里可以不用强调，比如曝光、点击的埋点。但是像上报时机有多个的情况，则需要跟开发明确。比如失败事件，是后台返回失败才算失败，还是前端抛出失败提示就算失败。
**上线后的观察与分析**
4) **对比验收数据**
    1）上线后对比数据是否符合预期
    同期对比：实验组与对比组同期整体对比，看分组的业务数据提升或降低效果。比如看某个功能的转化率或某个业务的千次曝光收入等。基本上从同期对比就可以得出，新功能对业务指标是起到正向还是负向的影响。
    前后对比：某些场景下需要。因为同期对比，需要开发做灰度切量的功能支持。所以如果新功能效果是显而易见的，且灰度功能做起来比较耗资源，我们可以选择上线后全覆盖，通过前后对比来看数据效果。
    2）上线后分析新功能是否带来长期价值
    一般情况，新功能只要看是否满足业务目标就足够了，但是我们还需要关注长期价值。一个好产品需要具备对用户有效用、对企业有收益、可持续这三个属性。
    eg: 关注新功能的精准留存。如果用户有持续使用新功能，那说明新功能具备长期价值，值得继续深挖；如果用户只使用一次新功能，那说明我们对需求把控没有到位或新功能没有很好地满足用户需求。
    3）上线后探索新功能的更多可能性
    分析新功能本身的数据，得到下一步优化的方向或获得需求洞察。
    eg:漏斗分析看每一步的转化率，分析漏损在哪里   
      比如分客群看使用新功能的情况，分析哪个客群是新功能的核心客群   
      比如看用户使用新功能的频率和时间分布，分析用户对新功能的使用习惯   
5) **分析数据原因**
   一般来说，分析数据背后的原因，分为客观原因和主观原因：
    1）客观原因
    由于改变客观环境，带来的数据变化。
    eg: 缩短用户操作路径，减少用户操作   
        优化页面布局，使主要功能更聚焦   
        优化性能，提高接口返回数据速度，降低失败率
        增加场景，提高曝光从而提高收入等。
    2）主观原因
    由于改变用户的主观意愿，带来的数据变化。比如增加奖励刺激，提高用户参与欲望；优化素材投放，提高用户点击欲望；客群本身的质量原因等。
6) **制定后续规划**
   根据新功能的数据结论及原因，确定接下来是要继续优化还是改变方向。   
   继续优化: 保留新功能，下一步计划是放量或优化后放量；
   改变方向: 现有功能没有符合预期，但是从现有数据获得新洞察，可以换个方向尝试。
**abtest**
## 6.预测类
### 如何做电商平台的销量预测   
对数据要进行收集，搜集除已有销量数据之外的额外信息（比如天气、地点、节假日信息等）, 预处理   
特征转换: 销售日期, 产品特征(款式、颜色、质地以及这款产品是否是限量版等)   
建模: 随机森林,SVM   
样本抽样，参数调参   
上线后迭代：根据实际的A/B testing和业务人员的建议改进模型   
指标分析：不知看销量，业务对接、预测精度、模型可解释性和产业链整体能力等因素综合考虑   
### 影响销量预测结果的要素需要考虑哪些
需求动向：流行趋势，爱好变化、生活形态变化、人口流动   
经济变动：国家经济增长率等指标变动   
竞争动向：竞争对手的目标市场，产品价格高低，促销与服务措施   
政府/消费者团体的动向   
营销策略：市场定位、产品政策、价格政策、渠道政策、广告及促销政策   
销售政策：管理内容、交易条件或付款条件，销售方法   
生产状况：货源是否充足
## 估算一个广告给头条带来多少新增用户
* 看以往这个渠道广告投放的历史数据，做一个机器学习模型
* 在这个渠道下，通过相似的竞争对手的产品（内容相似，目标客户相似）投放后的效果做评估，投放效果可以通过热搜关键词变化和应用下载量来看
* 对比其他渠道投放后的新增客户记录，假设检验看客单价是否相同

 
## 6.100万预算，红包补贴，增加外卖订单量。
分析思路：关键词：时间，RFM模型角度->个体角度   
目标：赚钱   
对象：建立人群，高价，沉睡，新用户->公司发展阶段策略不同，需求->裂变，分钱比率，测算订单量，目标100w，客单价多少钱，能换多少订单和销售额。销售额/100w   
宏观：南美市场，拉新，裂变，拉新做分享->高频高价分享补贴   
活跃用户二八，二成来源于哪里，大金额，给裂变   
Eg:饿了么：刚打仗时->拉新(激活沉睡)，老用户沉淀。后期->（老用户分享）。最近->留存（会员）。饱和（争夺商家）
## RFM模型
## 数据埋点  

## 2.在搜索中增加保留历史浏览记录这个功能
### 作为数据分析师会怎么去评估这个功能是否应该上线
### 需要去看那些指标
### 假设现在这个功能已经上线了，需要优化，你有哪些优化的想法
## 3.在北京开一家水果店会考虑哪些因素？如果要开分店还要考虑啥因素？
附近的商圈，附近的交通，店门口每日经过人数，经过的人数的构成，能见到这个店面的距离范围，竞争对手的数量
## 4.UBER现在有一个发放优惠券的活动，该如何评估这个活动带来的ROI 的影响
（投资回报率）ROI=［（收入－成本）／投入］＊100% 
## 5.然后问有没有觉得哪个APP的交互界面或者用户体验不是很好的
我说了快手的界面感觉不是很好，不太喜欢双排列模式（快手的粉丝不要喷我，纯属个人意见）。下面就进入了双排列模式和整屏模式的连环问题。分别说下两种模式的优缺点，如何判断两种模式的效果差异（AB测试），如果经过AB测试发现确实效果存在显著差异，通过哪些指标分析那种排列模式确实不好
## 7.引入一个新功能后，如何评价该新功能的有效性
对于新功能需要关注它受欢迎的情况（功能活跃比），被重复使用的情况（重复使用率），对于引入功能时确定的关键衡量指标的影响（比如对于转化率、对于用户使用时长），即目标指标是否改善；注意新功能引入之后，对于总体北极星指标或者总体用户留存的影响，以免该功能导致局部改善但是整体损失；最后可以通过分析功能引入之后用户使用路径和关键行为的变化，或者直接使用问卷和访谈调查反馈。
## 8.日活(DAU)：APP指标体系的搭建，用户的LTV，如何预测，用户粘性怎么看，怎么提高APP用户粘性，APP新功能如何评估
APP评价指标：日活、用户数、留存率   
DAU下降分析   
设计游戏综合表现指标、流量分配：   
   
## 11.抖音要现在有两个新功能，直播跟私信   
### 你怎么利用这两个功能的现状来评估，应该重点推广哪一个功能（面试官有提示，这两个功能类型不同之类的）   
### 你推广了这个功能之后，怎么评估推广的效果   
A：平均停留时长并不是一个非常好的指标，因为有可能只是打开了视频而一直没有观看，题目又说是越新的涨幅越大，可以考虑一下是否是app与新机型的兼容性问题，导致app视频打开时一直都在加载中，如果是这样那就比较危险了。所以如果想要验证这个假设，可以同期查看这个时候的评论，投诉，舆情，新增，流失等等数据，如果新机型用户的这些数据变化大且是增长的话，那么基本可以认为是兼容性问题了。   
对这两个功能做abtest(可能我自己挖坑说了abtest)，怎么控制实验组，对照组的人数（目前假设抖音日活1.5亿人）
## 数据埋点分类
点击事件， 曝光事件，页面停留时间事件
## app相关：
1. 抖音的优缺点，你印象最深的抖音的功能，怎么评估这个功能的效果
2. 设计一个提高直播收入的方案，如果李佳琦来抖音直播，怎么评估直播效果，大概就这些。
3. 如何估算一个节目的广告给头条能带来多少新增用户，给出估算思路和大致数值
4. 腾讯说去年20%的微信用户是ios用户，但是报告显示苹果只占全部手机销量的百分之8，请问这可能吗
5. 长视频跟短视频有什么区别
## 种西瓜问题
1. 一个果农种西瓜有100亩地。有一个卖肥料地推销他的肥料，说可以提高30%产量。
果农第一年在10亩地中试验，的确可以达到30%的提升。第二年全量使用，结果只有5%的提升，这是什么原因导致的？想出一个方法评估这一个肥料真实提高。
2. 果农拉西瓜出去卖。拉100斤西瓜，然后每斤成本5元，卖10元一斤，卖完了所有的西瓜，赚了500元。请问果农怎么提高收入？（每天都只有100斤西瓜的供应量）
3. 提高单价，会导致销量降低。假设，销量与单价之间满足销量y=a*单价x+b的函数。果农最大收益是多少？果农要用什么策略来提高价格？

 
## 留存：
留存：
```
预测周活 = 前一周留存用户(前一周活跃人数*周留存率)+周新增用户+周回流用户 
预测日活 = （日均活跃用户数 / 周活跃用户数）* 预测周活
```
预给一个每天新增用户30万，给次日到365天的留存，算一年以后的用户数。   
假如新增用户还是30万，所有留存求和是50，算一年以后的用户数   
有一个广告，如果上线，收入会每天增加2%，但是留存每天减少1.5%，现在每天收益是500万，新增用户30万，每吸收一个用户的成本是6块钱，那么判断一下广告要不要上线？   
## 异常指标归因：
1. 周期性下降
突然下降
3. 确定数据准确性：
4. 去除外部影响pest
内部：产品的迭代
日活下降：往下拆维度指标，新老用户，性别，
新客户：渠道：地铁站，地域，机型ios/andoroid。
留存，日活，
怎么去优化提升
指标体系建设：解决问题：这个效果好不好，点击率，停留时长，互动率。
常用的app

计算：
成本利润率= 利润（赚了多少） /  投入（成本），反映的是成本和利润的关系，衡量我的利润是否再生投入资本（资金回流），这个是站在资金回转时效的角度去看的。   
销售利润率= 利润（赚了多少）/  销售（销售收入），反映销售额和利润的关系，衡量利润情况是否达到目标需求，这是站在一盘生意的情况上看的。   
投资回报率（ROI）=产出（销售收入）/  投入（成本），反映投入和产出的关系，衡量我这个投资（花了多少钱）值不值得，能给到我多少价值的东西（非单单的利润），这个是站在投资的角度或长远生意上看的。

## 电商数据指标搭建
流量指标：
转化指标：
营运指标：
![营运指标](https://pic1.zhimg.com/80/d68753a109de6257e205d42a26c775a8_1440w.jpg?source=1940ef5c)
会员指标：
财务指标：

## 对用户进行分层


# 三. SQL：
## 题目集
>[数据库](https://leetcode-cn.com/problemset/database/)
>[组合两个表](https://leetcode-cn.com/problems/combine-two-tables/)
>[第二高薪水](https://leetcode-cn.com/problems/second-highest-salary/)
>[第n高](https://leetcode-cn.com/problems/nth-highest-salary/)
>[分数排名](https://leetcode-cn.com/problems/rank-scores/)
>[连续出现的数字](https://leetcode-cn.com/problems/consecutive-numbers/)
>[连续三个数字](https://leetcode-cn.com/problems/consecutive-numbers/)
>[超过经理的员工](https://leetcode-cn.com/problems/employees-earning-more-than-their-managers/)
>[查找重复电子邮箱](https://leetcode-cn.com/problems/duplicate-emails/)
>[删除重复电子邮箱](https://leetcode-cn.com/problems/delete-duplicate-emails/)
>[从不订购的客户](https://leetcode-cn.com/problems/customers-who-never-order/)
>[部门最高的员工](https://leetcode-cn.com/problems/department-highest-salary/)
>[部门前三高工资的员工](https://leetcode-cn.com/problems/department-top-three-salaries/)

## 1.	除了distinct外还有什么方法去重
Where + group by
## 2.	窗口函数：
```
<窗口函数> over (partition by <用于分组的列名>
                order by <用于排序的列名>)
```
函数：
```
专用：rank, dense_rank, row_number
聚合：sum. avg, count, max, min
```
## 3.	partition by 和 group by 的区别
partition by统计的每一条记录都存在，而group by将所有的记录汇总成一条记录
## 4.	窗口函数里的排序函数
ROW_NUMBER()函数:查询出来的每一行记录生成一个序号，依次排序且不会重复
`select ROW_NUMBER() OVER(order by [SubTime] desc) as row_num,* from [Order] order by [TotalPrice] desc`
RANK()函数:考虑到了over子句中排序字段值相同的情况
`select RANK() OVER(order by [UserId]) as rank,* from [Order]` 
DENSE_RANK()是排序，dense_rank函数在生成序号时是连续的，而rank函数生成的序号有可能不连续
`select DENSE_RANK() OVER(order by [UserId]) as den_rank,* from [Order]`
NTILE:可以对序号进行分组处理，将有序分区中的行分发到指定数目的组中
`select NTILE(4) OVER(order by [SubTime] desc) as ntile,* from [Order]`
![rank](https://raw.githubusercontent.com/TheonLiu/DA-Notes/main/pics/rank.png)

## 5. 窗口函数里的聚合函数
聚合函数作为窗口函数，可以在每一行的数据里直观的看到，截止到本行数据，统计数据是多少（最大值、最小值等）。同时可以看出每一行数据，对整体统计数据的影响。   
    累计求和：  
    ```
    select product_id, product_name, sale_price,
        sum(sale_price) over (order by product_id) as current_sum
    from Product;
    ```
    累计求平均
    ```
    select product_id, product_name, sale_price,
        avg(sale_price) over (order by product_id) as current_sum
    from Product;   
    ```
## 6. 窗口函数偏移函数
    LAG：向下偏移
    LEAD：向上偏移
    ```
    LAG (scalar_expression [,offset] [,default])
        OVER ( [ partition_by_clause ] order_by_clause )
    LEAD ( scalar_expression [ ,offset ] , [ default ] ) 
        OVER ( [ partition_by_clause ] order_by_clause )
    ```
    sclar_expression: 偏移的对象，即 旧列；
    offset: 偏移量；eg: offset=n，表示偏移了 n 行数据；默认值是1，必须是正整数；
    default: 偏移后的偏移区的取值；
## 7.	给主播id，主播类型，主播粉丝数，求每个类型主播粉丝数top100
用rank() over (partition by 类型 order by 粉丝数 desc) group by 主播类型 然后外头再套一层select *  where rank<=100
## 8.	sql执行顺序：
    from -> join -> on -> where-> group by(开始使用select中的别名，后面的语句中都可以使用)-> avg,sum.... -> having ->select -> distinct -> order by-> limit 
## 9.  INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN 
## 10. 等值连接，笛卡尔积
## 11.  UNION 和UNION ALL的区别
    UNION: 结果集进行并集,不包括重复行
    UNION ALL：结果取并集，包括重复行
## 12.  SQL行列转换
## count(1)：
就是统计在分组中，每一组对应的行数或项数。效率和作用和count(*)相同
## DATE_SUB(date,INTERVAL expr type)
从日期减去指定的时间间隔
date 参数是合法的日期表达式
expr 参数是您希望添加的时间间隔
type 参数 DAY WEEK等
## 判断空
is null / is not null

## Ifnull (expression, alt_value)
处理空值
## 去语义
' '
## lead
## delete语句
## 日期
NOW()	返回当前的日期和时间
CURDATE()	返回当前的日期
CURTIME()	返回当前的时间
DATE()	提取日期或日期/时间表达式的日期部分
EXTRACT()	返回日期/时间按的单独部分
DATE_ADD()	给日期添加指定的时间间隔
DATE_SUB()	从日期减去指定的时间间隔
DATEDIFF()	返回两个日期之间的天数
DATE_FORMAT()	用不同的格式显示日期/时间
## 主键/外键
主键：每个表必须有，唯一，不为空
外键：指向另一个表中的主键
# 四. Hive：
1.  hive, hadoop的原理
1.	与mysql的区别：map-reduce、数据吞吐量量
5.	hive和mysql都支持不等式关联吗
6.	数据倾斜

# 五. 统计：
## 1.	皮尔森相关系数以及如何解读，相关、独立、线性相关区别
Pearson 相关系数是用协方差除以两个变量的标准差得到
如果相互独立，则这两个随机变量一定是不相关的
不相关的随机变量，不一定是相互独立的
## 2. 讲一下A/B实验
**AB test**：
1. **指标**：CTR
2. **变体**：新的推荐策略
3. **假设**：新的推荐策略可以带来更多的用户点击
    H0：功能优化后与优化前没有差异，u2-u1=0
    H1：功能优化后于优化前有差异，u2-u1≠0
    u为点击率
4. **收集数据**：以下B组数据为我们想验证的新的策略结果数据，A组数据为旧的策略结果数据。实验组7天点击率，对照组7天点击率。
5. **样本量**的四个影响因素：
    * 显著性水平（α）：显著性水平越低，对实验结果的要求也就越高，越需要更大的样本量来确保精度
    * 统计功效（1 – β）：统计功效意味着避免犯二类错误的概率，这个值越大，需要的样本量也越大
    * 原始版本转换率,最小提升比例
    * （均值差异（μA-μB）：如果两个版本的均值差别巨大，也不太需要多少样本，就能达到统计显著）
    * （标准差（σ）：标准差越小，代表两组差异的趋势越稳定。越容易观测到显著的统计结果）
6. **选择检验**：同统计日之间是有随机波动的差异，而且实验组和对照组流量相等且随机，可以认为样本来自同一个总体。实验组是对同一天的对照组进行优化的结果，所以可以采用相关样本t检验
确定显著性水平：a=0.05
6. **计算统计量**：相关样本t检验是以每一组数据的差值作为检验的，所以以点击率差作检验，确定七组差值的均值md，求出样本方差开根号，代入t分数
7. **查表**
8. **注意事项**
   * 时间
   测试时间=最小测试样本量/每日流量
   用户行为周期（工作日和周末）
   用户适应周期
   * 样本质量
    检验样本有效性
    AA测试：旧版本90%，新版本10%。旧版本90%切分出两个10%，查看是否有显著性差异。如果有显著性差异说明有问题。


### 定义
在同一时间维度，分别让组成成分相似的访客群组访问这些版本，收集各群组的用户体验数据和业务数据，最后分析、评估出最好版本，正式采用
### 好处
消除不同意见，提高团队效率（选择不同UI界面）。
通过对比实验，验证问题原因（漏斗模型无效点击）。
建立科学运营优化体系，避免过度依赖人，降低人为风险，有效知识沉淀
### 如何分组
假设Group1上的实验结果为 r1, Group2上的实验结果为r2，则AB测试的差异是 r = r1 − r2，r是依赖于测试样本的随机变量，应该满足：
**无偏性**：假设在1%流量上某功能可以提高10%的点击率，那么在全量上也应该大约提高10%
**低方差**。r rr是一个随机变量，方差越小，可靠性越高。
**假设检验**：
H0：假定总体没有显著差异，或是H0落在接收域
H1：题目中希望证明成功的假设
最小化的都是 Type 1 Error，即尽量避免在H0实际正确的时候拒绝掉H1
置信区间：有95%的机会，真实值落在我们的这个置信区间里
置信度：
**P值的含义**：在假设原假设（H0）正确时，出现现状或更差的情况的概率。对于观察到的采样，能获得的最小的显著性水平，就是p值。
**F检验**：两个卡方分布相处
**T检验**：主要用于样本含量较小（例如n < 30），总体标准差σ未知的正态分布，比较两个平均数的差异是否显著。（自由度 1的卡方/自由度为n-1的卡方分布）
**Z检验**：一般用于大样本平均值差异性检验的方法。标准正态分布的理论来推断差异发生的概率，从而比较两个平均数的差异是否显著
**卡方检验**: n个标准正态分布的随机变量的平方和构成一新的随机变量
**中心极限定理**：不管样本总体服从什么分布，当样本数量足够大时，样本的均值以正态分布的形式围绕总体均值波动
**两类错误**
第一类错误：原假设是正确的，却拒绝了原假设。(错杀好人)
第二类错误：原假设是错误的，却没有拒绝原假设。(放走坏人)
![统计量](https://pic1.zhimg.com/v2-97e2cd6235a3733611d65635c849f730_r.jpg)
![Z](https://pic4.zhimg.com/80/v2-fc83557e85fb7e827337e64eb06be347_1440w.jpg)

## 3.	贝叶斯公式
P(Bi|A) = P(Bi)P(A|Bi) /EP(Bj)P(A|Bj)
## 4.	协方差的含义，协方差和相关系数的关系


**ABtest例题**：
* 某厂生产日光灯管。以往经验表明，灯管使用时间为1600h，标准差为70h，在最近生产的灯管中随机抽取了55件进行测试，测得正常使用时间为1520h。在0.05的显著性水平下，判断新生产的灯管质量是否有显著变化。
![日光灯](https://img-blog.csdnimg.cn/20200223221946541.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg1MjY3NA==,size_16,color_FFFFFF,t_70)
Tips：
H0: 新灯管质量与旧灯管没有显著性差异，即新灯管的平均值u=老灯管的平均值1600
通过查表可知，当Z值=3.99时，在统计学上就已经可以证明 - 有100%的把握拒绝原原假设了。
* 点击率等比率对比
广告优化那本书的Page32，有一个类似的很好的例题。
![显著性](https://img-blog.csdnimg.cn/20200513142504270.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg1MjY3NA==,size_16,color_FFFFFF,t_70)
**AB测试**：
[AB测试例题](http://www.itheima.com/news/20200715/171142.html)
 
# 六：机器学习：
[机器学习流程](https://www.jianshu.com/p/afa0facbe625)
## 1. 数据收集与探索性分析
### 如何看待基础性的工作，如数据清洗、数据抽取这些？

## 2. 数据预处理与特征工程

### 特征工程怎么做的
分解类别属性（01二元属性），特征分区（标量，比如年龄）交叉特征（组合的特征要比单个特征更好时），特征选择（修剪特征来达到减少噪声和冗余），特征缩放（岭回归） 数据标准化，特征提取（降维）
### 如果取出的数据中存在NULL，该如何做
1）	平均值，中位数，众数，随机数
2）	将变量映射到高维空间（2个值->3个值，男女null）。连续：平滑处理
3）	根据欧式距离或Pearson相似度，来确定和缺失数据样本最近的K个样本，将这K个样本的相关feature加权平均来估计该样本的缺失数据。
### 如果因为写的代码出现问题，导致取数出现NULL，该如何做
### 数据清洗（完整性，唯一性，权威性，合法性，一致性）
唯一性：去重。合法性：人工处理，设置警告。
### 偏态分布怎么处理
### 归一化好处
归一化的好处主要有两点：
**加快收敛速度**：在进行梯度下降的过程中，如果不进行归一化，那下降过程很可能会是“之”字形，归一化后每一步都朝着损失函数最低点前进。
**提升模型效果**：如果不进行归一化，模型可能会偏向尺度较大的特征，导致模型交过变差。
AdaBoost、GBDT、XGBoost、LR、SVM之类的最优化算法需要归一化；而决策树、RF这类的概率模型主要关注变量的分布，是否缩放不影响分裂点，所以不需要归一化。

### 降维:
**PCA**:
**PCA缺点**
**高维数据能适用PCA吗**
**类别变量onehot能用PCA吗**
高维度特征数据预处理方法。原有n维特征的基础上重新构造出来的k维特征。保留相互正交的维度，去除方差几乎为0的维度

**降维**
### 解释维度灾难，如何解决？
### knn如何处理高维特征？
### kmeans如何处理高维特征？
## 3. 数据集分割
**在保留交叉验证**（hand-out cross validation）中，随机将训练样本集分成训练集（training set）和交叉验证集（cross validation set）,比如分别占70%，30%。然后使用模型在训练集上学习得到假设。最后使用交叉验证集对假设进行验证，看预测的是否准确，选择具有误差小的模型。
**k折交叉验证**（K-fold cross validation），就是把样本集S分成k份，分别使用其中的(k-1)份作为训练集，剩下的1份作为交叉验证集，最后取最后的平均误差，来评估这个模型。
**留一法**（leave one out， LOO）就是m-fold cross validation，m是样本集的大小，就是只留下一个样本来验证模型的准确性
## 4. 模型的选择与训练
### 机器学习分类：
**监督机器学习**：线性回归；逻辑回归；随机森林；梯度下降决策树；支持向量机（SVM）；神经网络；决策树；朴素贝叶斯；邻近邻居（Nearest Neighbor）
**无监督学习**：K-means聚类；KNN；PCA；关联规则
**半监督学习**：
**强化学习**：Q-learning；蒙特卡洛树搜索；MDP
### 线性非线性
线性模型：
1) 广义线性模型：逻辑回归（二分类）；softmax回归（多分类）；Ridge，LASSO
     Poisson regression，Gamma regression，Tweedie regression->link function不同；
2) 时间序列模型:自回归（AR）,还有ARIMA，SARIMA
   
非线性模型：SVM，KNN，决策树，深度学习模型
### 简单模型和复杂模型区别在哪
### softmax损失函数
交叉熵
****
### Linear Regression:

**$L_1$ and $L_2$ norms**
* Norm: length of vectors
* $L_2$ norm (aka. Euclidean distance)
  * $||a|| = ||a||_2 \equiv \sqrt{a_1^2 + ... + a_n^2}$
* $L_1$ norm (aka. Manhattan distance)
  * $||a||_1 \equiv |a_1| + ... + |a_n|$

#### 线性回归优化问题:损失函数
* To find $\beta$, minimize the **sum of squared errors**:
  * $SSE/RSS = \sum_{i=1}^n (y_i - \sum_{j=0}^m X_{ij}\beta_{j})^2$
* Setting derivative to zero and solve for $\beta$: (normal equation)
  * $b = (X^TX)^{-1}X^{T}y$
  * Well defined only if the inverse exists
  
### 逻辑回归
#### 模型:
* $P(Y = 1 | x) = \frac{1}{1 + \text{exp}(-x^T\beta)}$
#### 分类规则:
  * Class "1" 
      * If $P(Y=1 | x) = \frac{1}{\exp(-x^{T}\beta)} > \frac{1}{2}$
      * Else class "0"
  * Decision boundary (line): 
      * $P(Y = 1 | x) = \frac{1}{1 + \text{exp}(-x^T\beta)} = \frac{1}{2}$
      * Equivalently, $P(Y = 0 | x) = P(Y = 1 | x)$
#### 线性vs逻辑回归
* Linear regression
  * Assume $\epsilon \sim N(0, \sigma^2)$
  * Therefore assume $y \sim N(X\beta, \sigma^2)$
* Logistic regression
  * Assume $y \sim Bernoulli(p = logistic(x^{T}\beta))$
****
### svm:
#### Hard-margin SVM loss:
  * $l_\infty = 0$ if prediction correct
  * $l_\infty = \infty$ if prediction wrong
#### Soft-margin SVM loss: (hinge loss)
  * $l_h = 0$ if prediction correct
  * $l_h = 1 - y(w'x + b) = 1 - y\hat{y}$ if prediction wrong (penalty)
  * Can be written as: $l_h = max(0, 1 - y_i (w'x_i + b))$
**svm如何处理高维特征**
kernel
**SVM优化过程**
#### LR和SVM区别
loss function不同
线性SVM依赖数据表达的距离测度，所以需要对数据先做normalization，LR不受其影响
SVM自带正则
#### LR，SVM中数据之间应该满足什么条件 
凸优化问题
如果不考虑核函数，都只能处理线性
### Kernel
目的:处理非线性分类
原理:在特征空间可以表示成点成的函数
****
### Kmeans，KNN区别
KNN：分类算法，距离最近的k个样本数据的分类来代表目标数据的分类
Kmeans：k-均值聚类分析
**kmeans如何处理异常点**
****

### Ensemble：将多个分类方法聚集在一起，以提高分类的准确率
分类：Bagging（eg:随机森林），Boosting（eg:AdaBoost，XGboost，GBDT），Stacking
**Bagging**：有放回选取，训练集之间是独立。并行
  * Parallel sampling
  * Minimise variance
  * Simple voting
  * Classification or regression
  * Not prone to overfitting
**Boosting**：训练集不变，分类器中的权重发生变化，权值是根据上一轮的分类结果错误率进行调整。顺序
  * Iterative sampling
  * Target "hard" instances
  * Weighted voting
  * Classification or regression
  * Prone to overfitting (unless base learners are simple)
### GBDT过程
[GBDT过程](https://blog.csdn.net/yingfengfeixiang/article/details/79728639)
### GBDT调参
[调参](https://www.cnblogs.com/pinard/p/6143927.html)
划分时考虑的最大特征数max_features：默认全部
决策树最大深度max_depth
内部节点再划分所需最小样本数min_samples_split
叶子节点最少样本数min_samples_leaf：叶节点过少会被剪枝
叶子节点最小的样本权重和min_weight_fraction_leaf
最大叶子节点数max_leaf_nodes
节点划分最小不纯度min_impurity_split:
### GBDT和决策树(RF)
GBDT和随机森林的不同点：
GBDT:用分类器（如CART、RF）拟合损失函数梯度。损失函数:期望输出与分类器预测输出的查，即bias
RF: 自采样,属性随机。variance
* 组成随机森林的树可以是分类树，也可以是回归树；而GBDT只由回归树组成；
* 组成随机森林的树可以并行生成；而GBDT只能是串行生成；
* 对于最终的输出结果而言，随机森林采用多数投票等；而GBDT则是将所有结果累加起来，或者加权累加起来；
* 随机森林对异常值不敏感，GBDT对异常值非常敏感；
* 随机森林对训练集一视同仁，GBDT是基于权值的弱分类器的集成；
* 随机森林是通过减少模型方差提高性能，GBDT是通过减少模型偏差提高性能
### GBDT和XGBoost的区别（至少3方面）
GBDT：将目标函数泰勒展开到一阶，新的基模型寻找新的拟合标签。xgboost加入了和叶子权重的L2正则化项。自动处理缺失值特征的策略.
     每一次的计算是为了减少上一次的残差，GBDT在残差减少（负梯度）的方向上建立一个新的模型。
Xgboost：将目标函数泰勒展开到了二阶，
怎么提高ensemble的表现：选取分裂点，分裂位置
基本精确的贪心算法，近似算法，带权重的分位数草图
### GBDT剪枝是怎么样的
基于cart：代价-复杂度剪枝法。
代价(cost) ：主要指样本错分率；复杂度(complexity) ：主要指树t的叶节点数，(Breiman…)定义树t的代价复杂度(
### 树的剪枝
* 前剪枝( Pre-Pruning)
通过提前停止树的构造来对决策树进行剪枝，一旦停止该节点下树的继续构造，该节点就成了叶节点。
剪枝原则有：a.节点达到完全纯度；b.树的深度达到用户所要的深度；c.节点中样本个数少于用户指定个数；d.不纯度指标下降的最大幅度小于用户指定的幅度。
* 后剪枝( Post-Pruning)
首先构造完整的决策树，允许决策树过度拟合训练数据，然后对那些置信度不够的结点的子树用叶结点来替代。
### 随机森林为什么随机
训练集是随机独立选取的
### 决策树和随机森林优缺点
**决策树**：
容易过拟合，导致泛化能力不强。Sl：设置节点最少样本数量和限制决策树深度。
有些比较复杂的关系，决策树很难学习，比如异或。Sl：用神经网络
特征的样本比例过大，生成决策树容易偏向于这些特征。SL：调节样本权重
**随机森林**：
1）	【输入数据】是随机的从整体的训练数据中选取一部分作为一棵决策树的构建，而且是有放回的选取
2）	每棵决策树的构建所需的【特征】是从整体的特征集随机的选取的;
两个随机性的引入，使得随机森林不容易陷入过拟合
处理很高维度（feature很多）的数据，并且不用做特征选择
能够检测到feature间的互相影响
****
### 优化问题
最速下降法（梯度下降法），牛顿法，共轭梯度法，拟牛顿法

## 5. 模型的评价
### 模型评估指标的选择
分类任务：准确率和错误率
查准率和查全率：P=TP/TP+FP，R=TP/TP+FN
### 模型怎么判断过拟合，过拟合怎么了

### 知道哪些距离，适用场景是什么
> (几种距离度量方法的简介、区别和应用场景)[https://blog.csdn.net/ou_nei/article/details/88371615]

欧氏距离: 两点间在空间中的距离
曼哈顿距离: 两个点在标准坐标系上的绝对轴距总和(地图类)
汉明距离：两个等长字符串对应位置的不同字符的个数
皮尔逊相关系数：
如果数据存在“分数膨胀“问题，就使用皮尔逊相关系数
如果数据比较密集，变量之间基本都存在共有值，且这些距离数据都是非常重要的，那就使用欧几里得或者曼哈顿距离
如果数据是稀疏的，就使用余弦相似度
在线音乐网站的用户评分例子https://blog.csdn.net/Gamer_gyt/article/details/78037780
由皮尔逊相关系数可以得出评分分值差别很大的两个用户其实喜好是完全一致的。 找相似用户。
如果数据的维度不一样，用欧氏距离或曼哈顿距离是不公平的。   在数据完整的情况下效果好
### ROC曲线 与 AUC怎么算
ROC：正负样本的分布变化的时候，ROC曲线能够保持不变
     纵坐标：真正率 TP/TP+FN
     横坐标：假正率FP/FP+TN
AUC：ROC下方面积大小


## 6. 模型的部署


[案例分析](https://zhuanlan.zhihu.com/p/23908522)
